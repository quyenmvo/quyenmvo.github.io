<!doctype html><html lang=en dir=auto><head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="noindex, nofollow"><title>Diffusion Models: An In-depth Overview | Q'Corner</title>
<meta name=keywords content="first"><meta name=description content="Introduction Diffusion models have emerged as one of the most advanced methods in the field of generative modeling. They have broken the long-standing dominance of GANs in image generation tasks and have shown potential in various other fields, including computer vision, natural language processing, temporal data modeling, multimodal modeling, machine learning, and interdisciplinary applications such as computational chemistry and medical image reconstruction.
Diffusion models have increasingly achieved significant successes across multiple domains."><meta name=author content="Quyen M. Vo"><link rel=canonical href=https://canonical.url/to/page><link crossorigin=anonymous href=/assets/css/stylesheet.b072c09c6597a4e86cf64b1f8790a4c5ced7f2e6e0a70a9053db11f16d83a31b.css integrity="sha256-sHLAnGWXpOhs9ksfh5Ckxc7X8ubgpwqQU9sR8W2Doxs=" rel="preload stylesheet" as=style><link rel=icon href=http://localhost:1313/favicon.ico><link rel=icon type=image/png sizes=16x16 href=http://localhost:1313/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=http://localhost:1313/favicon-32x32.png><link rel=apple-touch-icon href=http://localhost:1313/apple-touch-icon.png><link rel=mask-icon href=http://localhost:1313/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en href=http://localhost:1313/blogs/page/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><script id=MathJax-script async src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js></script><script>MathJax={tex:{displayMath:[["\\[","\\]"],["$$","$$"]],inlineMath:[["\\(","\\)"]]}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=http://localhost:1313/ accesskey=h title="Q'Corner (Alt + H)">Q'Corner</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=http://localhost:1313/blogs/ title=Blogs><span>Blogs</span></a></li><li><a href=http://localhost:1313/projects/ title=Projects><span>Projects</span></a></li><li><a href=http://localhost:1313/archives/ title=Archives><span>Archives</span></a></li><li><a href=http://localhost:1313/search/ title="Search (Alt + /)" accesskey=/><span>Search</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=http://localhost:1313/>Home</a>&nbsp;»&nbsp;<a href=http://localhost:1313/blogs/>Blogs</a></div><h1 class="post-title entry-hint-parent">Diffusion Models: An In-depth Overview</h1><div class=post-meta><span title='2020-09-15 11:30:03 +0000 +0000'>September 15, 2020</span>&nbsp;·&nbsp;8 min&nbsp;·&nbsp;1558 words&nbsp;·&nbsp;Quyen M. Vo</div></header><div class=toc><details><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><nav id=TableOfContents><ul><li><a href=#introduction>Introduction</a></li><li><a href=#denoising-diffusion-probabilistic-models>Denoising Diffusion Probabilistic Models</a><ul><li><a href=#forward-diffusion-process>Forward diffusion process</a></li><li><a href=#reverse-diffusion-process>Reverse diffusion process</a></li></ul></li><li><a href=#training-loss>Training Loss</a></li><li><a href=#conditioned-generation>Conditioned Generation</a><ul><li><a href=#classifier-free-guidance>Classifier-Free Guidance</a></li></ul></li><li><a href=#improving-diffusion-model-speed>Improving Diffusion Model Speed</a><ul><li><a href=#denoising-diffusion-implicit-model-ddim>Denoising Diffusion Implicit Model (DDIM)</a></li><li><a href=#latent-diffusion-model>Latent Diffusion Model</a></li></ul></li><li><a href=#model-architecture>Model Architecture</a><ul><li><a href=#u-net>U-Net</a></li><li><a href=#diffusion-transformer-dit>Diffusion Transformer (DiT)</a></li></ul></li><li><a href=#implementation>Implementation</a></li><li><a href=#conclusion>Conclusion</a></li><li><a href=#references>References</a></li></ul></nav></div></details></div><div class=post-content><h2 id=introduction>Introduction<a hidden class=anchor aria-hidden=true href=#introduction>#</a></h2><p>Diffusion models have emerged as one of the most advanced methods in the field of generative modeling. They have broken the long-standing dominance of GANs in image generation tasks and have shown potential in various other fields, including computer vision, natural language processing, temporal data modeling, multimodal modeling, machine learning, and interdisciplinary applications such as computational chemistry and medical image reconstruction.</p><p>Diffusion models have increasingly achieved significant successes across multiple domains. Recently, the Sora model demonstrated the capability to generate dynamic videos from text input alone. In this report, we will explore and elucidate the fundamentals of diffusion models, their image generation capabilities, and their architectural designs.</p><p>In this blog, we will explore the foundational concepts of diffusion models, the process of image generation, and the architecture of these models.</p><h2 id=denoising-diffusion-probabilistic-models>Denoising Diffusion Probabilistic Models<a hidden class=anchor aria-hidden=true href=#denoising-diffusion-probabilistic-models>#</a></h2><h3 id=forward-diffusion-process>Forward diffusion process<a hidden class=anchor aria-hidden=true href=#forward-diffusion-process>#</a></h3><p>Given a data point sampled from a real data distribution \(\mathbf{x}_0 \sim q(\mathbf{x})\), we define the forward diffusion process as the process that gradually destroys the data distribution by adding noise to the sample over \(T\) steps, creating a noisy sample sequence: \(\mathbf{x}_1, \dots, \mathbf{x}_T\).</p>$$
q(\mathbf{x}_t \vert \mathbf{x}_{t-1}) = \mathcal{N}(\mathbf{x}_t; \sqrt{1 - \beta_t} \mathbf{x}_{t-1}, \beta_t\mathbf{I}) \quad
q(\mathbf{x}_{1:T} \vert \mathbf{x}_0) = \prod^T_{t=1} q(\mathbf{x}_t \vert \mathbf{x}_{t-1})
$$<p>Note that \(\beta\) here is a time-dependent hyperparameter controlled by the variance schedule \(\{\beta_t \in (0, 1)\}_{t=1}^T\). The data sample \(\mathbf{x}_0\) gradually loses its recognizable features as \(t\) increases, and when \(T \to \infty\), \(\mathbf{x}_T\) becomes equivalent to an isotropic Gaussian distribution.</p><p>Let \(\alpha_t = 1 - \beta_t\) and \(\bar{\alpha}_{t} = \prod_{i=1}^t \alpha_i\). Rewriting (1), we get:</p>$$
\begin{aligned}
\mathbf{x}_t
&= \sqrt{1 - \beta_t} \mathbf{x}_{t-1} + \beta_t \boldsymbol{\epsilon}_{t-1} & \text{ ;with } \boldsymbol{\epsilon}_{t-1}, \boldsymbol{\epsilon}_{t-2}, \dots \sim \mathcal{N}(\mathbf{0}, \mathbf{I}) \\
&= \sqrt{\alpha_t}\mathbf{x}_{t-1} + \sqrt{1 - \alpha_t}\boldsymbol{\epsilon}_{t-1}\\
&= \sqrt{\alpha_t \alpha_{t-1}} \mathbf{x}_{t-2} + \sqrt{1 - \alpha_t}\boldsymbol{\epsilon}_{t-1} + \sqrt{\alpha_t (1 - \alpha_{t-1})} {\boldsymbol{\epsilon}}_{t-2}\\
&= \sqrt{\alpha_t \alpha_{t-1}} \mathbf{x}_{t-2} + \sqrt{1 - \alpha_t \alpha_{t-1}} \bar{\boldsymbol{\epsilon}}_{t-2}\\
&= \dots \\
&= \sqrt{\bar{\alpha}_t}\mathbf{x}_0 + \sqrt{1 - \bar{\alpha}_t}\boldsymbol{\epsilon}\\
q(\mathbf{x}_t \vert \mathbf{x}_0) &= \mathcal{N}(\mathbf{x}_t; \sqrt{\bar{\alpha}_t} \mathbf{x}_0, (1 - \bar{\alpha}_t)\mathbf{I})
\end{aligned}
$$<p>Generally, we need larger update steps as the sample becomes noisier, so \(\beta_1 < \beta_2 < \dots < \beta_T\) and \(\bar{\alpha}_1 > \dots > \bar{\alpha}_T\).</p><h3 id=reverse-diffusion-process>Reverse diffusion process<a hidden class=anchor aria-hidden=true href=#reverse-diffusion-process>#</a></h3><figure class=align-center><img loading=lazy src=images/DDPM.png#center></figure><p>We have the forward diffusion process that turns a sample \(\mathbf{x}_0\) into Gaussian noise. If we can reverse this process using \(q(\mathbf{x}_{t-1} \vert \mathbf{x}_t)\), we can reconstruct the sample from Gaussian noise \(\mathbf{x}_T \sim \mathcal{N}(\mathbf{0}, \mathbf{I})\). However, we cannot estimate \(q(\mathbf{x}_{t-1} \vert \mathbf{x}_t)\), so we will learn a model \(p_\theta(\mathbf{x}_{t-1} \vert \mathbf{x}_t)\) to approximate \(q(\mathbf{x}_{t-1} \vert \mathbf{x}_t)\).</p>$$
p_\theta(\mathbf{x}_{0:T}) = p(\mathbf{x}_T) \prod^T_{t=1} p_\theta(\mathbf{x}_{t-1} \vert \mathbf{x}_t) \quad
p_\theta(\mathbf{x}_{t-1} \vert \mathbf{x}_t) = \mathcal{N}(\mathbf{x}_{t-1}; \boldsymbol{\mu}_\theta(\mathbf{x}_t, t), \boldsymbol{\Sigma}_\theta(\mathbf{x}_t, t))
$$<p>Note that we can compute the reverse distribution when \(\mathbf{x}_0\) is known as follows:</p>$$
q(\mathbf{x}_{t-1} \vert \mathbf{x}_t, \mathbf{x}_0) = \mathcal{N}(\mathbf{x}_{t-1}; \tilde{\boldsymbol{\mu}}(\mathbf{x}_t, \mathbf{x}_0), \tilde{\beta}_t \mathbf{I})
$$<p>Applying Bayes&rsquo; theorem, we get:</p>$$
\begin{aligned}
q(\mathbf{x}_{t-1} \vert \mathbf{x}_t, \mathbf{x}_0)
&= q(\mathbf{x}_t \vert \mathbf{x}_{t-1}, \mathbf{x}_0) \frac{ q(\mathbf{x}_{t-1} \vert \mathbf{x}_0) }{ q(\mathbf{x}_t \vert \mathbf{x}_0) } \\
&\propto \exp \Big(-\frac{1}{2} \big(\frac{(\mathbf{x}_t - \sqrt{\alpha_t} \mathbf{x}_{t-1})^2}{\beta_t} + \frac{(\mathbf{x}_{t-1} - \sqrt{\bar{\alpha}_{t-1}} \mathbf{x}_0)^2}{1-\bar{\alpha}_{t-1}} - \frac{(\mathbf{x}_t - \sqrt{\bar{\alpha}_t} \mathbf{x}_0)^2}{1-\bar{\alpha}_t} \big) \Big) \\
&= \exp \Big(-\frac{1}{2} \big(\frac{\mathbf{x}_t^2 - 2\sqrt{\alpha_t} \mathbf{x}_t \mathbf{x}_{t-1} + \alpha_t \mathbf{x}_{t-1}^2 }{\beta_t} + \frac{ \mathbf{x}_{t-1}^2 - 2 \sqrt{\bar{\alpha}_{t-1}} \mathbf{x}_0 \mathbf{x}_{t-1} + \bar{\alpha}_{t-1} \mathbf{x}_0^2 }{1-\bar{\alpha}_{t-1}} - \frac{(\mathbf{x}_{t} - \sqrt{\bar{\alpha}_t} \mathbf{x}_0)^2}{1-\bar{\alpha}_t} \big) \Big) \\
&= \exp\Big( -\frac{1}{2} \big( (\frac{\alpha_t}{\beta_t} + \frac{1}{1 - \bar{\alpha}_{t-1}}) \mathbf{x}_{t-1}^2 - (\frac{2\sqrt{\alpha_t}}{\beta_t} \mathbf{x}_t + \frac{2\sqrt{\bar{\alpha}_{t-1}}}{1 - \bar{\alpha}_{t-1}} \mathbf{x}_0) \mathbf{x}_{t-1} + C(\mathbf{x}_t, \mathbf{x}_0) \big) \Big)
\end{aligned}
$$<p>where \(C(\mathbf{x}_t, \mathbf{x}_0)\) is a function not involving \(\mathbf{x}_{t-1}\). According to the probability density function of the Gaussian distribution, the mean and variance can be computed as follows:</p>$$
\begin{aligned}
\tilde{\boldsymbol{\mu}}_t (\mathbf{x}_t, \mathbf{x}_0)
&= (\frac{\sqrt{\alpha_t}}{\beta_t} \mathbf{x}_t + \frac{\sqrt{\bar{\alpha}_{t-1} }}{1 - \bar{\alpha}_{t-1}} \mathbf{x}_0)/(\frac{\alpha_t}{\beta_t} + \frac{1}{1 - \bar{\alpha}_{t-1}}) \\
&= (\frac{\sqrt{\alpha_t}}{\beta_t} \mathbf{x}_t + \frac{\sqrt{\bar{\alpha}_{t-1} }}{1 - \bar{\alpha}_{t-1}} \mathbf{x}_0) \frac{1 - \bar{\alpha}_{t-1}}{1 - \bar{\alpha}_t} \cdot \beta_t \\
&= \frac{\sqrt{\alpha_t}(1 - \bar{\alpha}_{t-1})}{1 - \bar{\alpha}_t} \mathbf{x}_t + \frac{\sqrt{\bar{\alpha}_{t-1}}\beta_t}{1 - \bar{\alpha}_t} \mathbf{x}_0\\
\tilde{\beta}_t
&= 1/(\frac{\alpha_t}{\beta_t} + \frac{1}{1 - \bar{\alpha}_{t-1}})\\
&= 1/(\frac{\alpha_t - \alpha_t \bar{\alpha}_{t-1} + \beta_t}{\beta_t (1 - \bar{\alpha}_{t-1})}) \\
&= \frac{\beta_t (1 - \bar{\alpha}_{t-1})}{1 - \bar{\alpha}_t} \\
q(\mathbf{x}_{t-1} \vert \mathbf{x}_t, \mathbf{x}_0) &= \mathcal{N}(\mathbf{x}_{t-1}; \tilde{\boldsymbol{\mu}}_t (\mathbf{x}_t, \mathbf{x}_0), \tilde{\beta}_t \mathbf{I})
\end{aligned}
$$<p>Thus, we can parameterize the mean \(\tilde{\boldsymbol{\mu}}(\mathbf{x}_t, \mathbf{x}_0)\) with a neural network with parameter \(\theta\), and the variance with a fixed schedule \(\beta_t\). A common approach is to parameterize \(\boldsymbol{\mu}_\theta(\mathbf{x}_t, t) = \frac{1}{\sqrt{\alpha_t}} \Big( \mathbf{x}_t - \frac{\beta_t}{\sqrt{1 - \bar{\alpha}_t}} \epsilon_\theta(\mathbf{x}_t, t) \Big)\).</p><h2 id=training-loss>Training Loss<a hidden class=anchor aria-hidden=true href=#training-loss>#</a></h2><p>As mentioned above, we will learn a model \(p_\theta\) to approximate \(q(\mathbf{x}_{t-1} \vert \mathbf{x}_t)\). We will minimize the negative log-likelihood: \(-\log p_\theta(\mathbf{x}_0)\). However, this function is not directly computable, so we need to use a technique similar to the Variational Autoencoder (VAE) called the Variational Lower Bound:</p>$$
\begin{aligned}
\log p_\theta(\mathbf{x}_0)
&\leq - \log p_\theta(\mathbf{x}_0) + D_\text{KL}(q(\mathbf{x}_{1:T}\vert\mathbf{x}_0) \| p_\theta(\mathbf{x}_{1:T}\vert\mathbf{x}_0) ) \\
&= -\log p_\theta(\mathbf{x}_0) + \mathbb{E}_{q(\mathbf{x}_{1:T} \vert \mathbf{x}_0)} \Big[ \log\frac{q(\mathbf{x}_{1:T}\vert\mathbf{x}_0)}{p_\theta(\mathbf{x}_{0:T}) / p_\theta(\mathbf{x}_0)} \Big] \\
&= -\log p_\theta(\mathbf{x}_0) + \mathbb{E}_{q(\mathbf{x}_{1:T}\vert\mathbf{x}_0)} \Big[ \log\frac{q(\mathbf{x}_{1:T}\vert\mathbf{x}_0)}{p_\theta(\mathbf{x}_{0:T})} + \log p_\theta(\mathbf{x}_0) \Big] \\
&= \mathbb{E}_{q(\mathbf{x}_{1:T}\vert\mathbf{x}_0)} \Big[ \log \frac{q(\mathbf{x}_{1:T}\vert\mathbf{x}_0)}{p_\theta(\mathbf{x}_{0:T})} \Big] \\
\text{Let } L_\text{VLB}
&= \mathbb{E}_{q(\mathbf{x}_{0:T})} \Big[ \log \frac{q(\mathbf{x}_{1:T}\vert\mathbf{x}_0)}{p_\theta(\mathbf{x}_{0:T})} \Big] \geq - \mathbb{E}_{q(\mathbf{x}_0)} \log p_\theta(\mathbf{x}_0)
\end{aligned}
$$<p>The objective function can be rewritten as a sum of KL-divergences:</p>$$
\begin{aligned}
L_\text{VLB}
&= \mathbb{E}_{q(\mathbf{x}_{0:T})} \Big[ \log\frac{q(\mathbf{x}_{1:T}\vert\mathbf{x}_0)}{p_\theta(\mathbf{x}_{0:T})} \Big] \\
&= \mathbb{E}_q \Big[ \log\frac{\prod_{t=1}^T q(\mathbf{x}_t\vert\mathbf{x}_{t-1})}{ p_\theta(\mathbf{x}_T) \prod_{t=1}^T p_\theta(\mathbf{x}_{t-1} \vert\mathbf{x}_t) } \Big] \\
&= \mathbb{E}_q \Big[ -\log p_\theta(\mathbf{x}_T) + \sum_{t=1}^T \log \frac{q(\mathbf{x}_t\vert\mathbf{x}_{t-1})}{p_\theta(\mathbf{x}_{t-1} \vert\mathbf{x}_t)} \Big] \\
&= \mathbb{E}_q \Big[ -\log p_\theta(\mathbf{x}_T) + \sum_{t=2}^T \log \frac{q(\mathbf{x}_t\vert\mathbf{x}_{t-1})}{p_\theta(\mathbf{x}_{t-1} \vert\mathbf{x}_t)} + \log\frac{q(\mathbf{x}_1 \vert \mathbf{x}_0)}{p_\theta(\mathbf{x}_0 \vert \mathbf{x}_1)} \Big] \\
&= \mathbb{E}_q \Big[ -\log p_\theta(\mathbf{x}_T) + \sum_{t=2}^T \log \Big( \frac{q(\mathbf{x}_{t-1} \vert \mathbf{x}_t, \mathbf{x}_0)}{p_\theta(\mathbf{x}_{t-1} \vert\mathbf{x}_t)}\cdot \frac{q(\mathbf{x}_t \vert \mathbf{x}_0)}{q(\mathbf{x}_{t-1}\vert\mathbf{x}_0)} \Big) + \log \frac{q(\mathbf{x}_1 \vert \mathbf{x}_0)}{p_\theta(\mathbf{x}_0 \vert \mathbf{x}_1)} \Big] \\
&= \mathbb{E}_q \Big[ -\log p_\theta(\mathbf{x}_T) + \sum_{t=2}^T \log \frac{q(\mathbf{x}_{t-1} \vert \mathbf{x}_t, \mathbf{x}_0)}{p_\theta(\mathbf{x}_{t-1} \vert\mathbf{x}_t)} + \sum_{t=2}^T \log \frac{q(\mathbf{x}_t \vert \mathbf{x}_0)}{q(\mathbf{x}_{t-1} \vert \mathbf{x}_0)} + \log\frac{q(\mathbf{x}_1 \vert \mathbf{x}_0)}{p_\theta(\mathbf{x}_0 \vert \mathbf{x}_1)} \Big] \\
&= \mathbb{E}_q \Big[ -\log p_\theta(\mathbf{x}_T) + \sum_{t=2}^T \log \frac{q(\mathbf{x}_{t-1} \vert \mathbf{x}_t, \mathbf{x}_0)}{p_\theta(\mathbf{x}_{t-1} \vert\mathbf{x}_t)} + \log\frac{q(\mathbf{x}_T \vert \mathbf{x}_0)}{q(\mathbf{x}_1 \vert \mathbf{x}_0)} + \log \frac{q(\mathbf{x}_1 \vert \mathbf{x}_0)}{p_\theta(\mathbf{x}_0 \vert \mathbf{x}_1)} \Big] \\
&= \mathbb{E}_q \Big[ \log\frac{q(\mathbf{x}_T \vert \mathbf{x}_0)}{p_\theta(\mathbf{x}_T)} + \sum_{t=2}^T \log \frac{q(\mathbf{x}_{t-1} \vert \mathbf{x}_t, \mathbf{x}_0)}{p_\theta(\mathbf{x}_{t-1} \vert\mathbf{x}_t)} - \log p_\theta(\mathbf{x}_0 \vert \mathbf{x}_1) \Big] \\
&= \mathbb{E}_q [\underbrace{D_\text{KL}(q(\mathbf{x}_T \vert \mathbf{x}_0) \parallel p_\theta(\mathbf{x}_T))}_{L_T} + \sum_{t=2}^T \underbrace{D_\text{KL}(q(\mathbf{x}_{t-1} \vert \mathbf{x}_t, \mathbf{x}_0) \parallel p_\theta(\mathbf{x}_{t-1} \vert\mathbf{x}_t))}_{L_{t-1}} \underbrace{- \log p_\theta(\mathbf{x}_0 \vert \mathbf{x}_1)}_{L_0} ]\\
&= \mathbb{E}_q [L_T + L_{T-1} + \dots + L_0 ] \\\\
\text{where: } L_T &= D_\text{KL}(q(\mathbf{x}_T \vert \mathbf{x}_0) \parallel p_\theta(\mathbf{x}_T)) \\
L_t &= D_\text{KL}(q(\mathbf{x}_t \vert \mathbf{x}_{t+1}, \mathbf{x}_0) \parallel p_\theta(\mathbf{x}_t \vert\mathbf{x}_{t+1})) \text{ for }1 \leq t \leq T-1 \\
L_0 &= - \log p_\theta(\mathbf{x}_0 \vert \mathbf{x}_1)
\end{aligned}
$$<p>Each KL term in \(L_\text{VLB}\) (except \(L_0\)) compares two Gaussian distributions. \(L_T\) is a constant so it can be ignored during training because $q$ has no parameters to learn and \(x_T\) is just Gaussian noise.</p><p>We need to recall that we are training a model that can approximate the conditional distribution of the reverse diffusion process \(p_\theta(\mathbf{x}_{t-1} \vert \mathbf{x}_t) = \mathcal{N}(\mathbf{x}_{t-1}; \boldsymbol{\mu}_\theta(\mathbf{x}_t, t), \boldsymbol{\Sigma}_\theta(\mathbf{x}_t, t))\). We will train (\boldsymbol{\mu}_\theta/) to predict $\tilde{\boldsymbol{\mu}}_t = \frac{1}{\sqrt{\alpha_t</p><h2 id=conditioned-generation>Conditioned Generation<a hidden class=anchor aria-hidden=true href=#conditioned-generation>#</a></h2><h3 id=classifier-free-guidance>Classifier-Free Guidance<a hidden class=anchor aria-hidden=true href=#classifier-free-guidance>#</a></h3><p>In certain scenarios, we generate samples conditioned on additional information without using an explicit classifier. This method, known as classifier-free guidance, enhances the model&rsquo;s flexibility and performance.</p><img loading=lazy src=images/classifier_free_guidance.png alt="Classifier-Free Guidance"><h2 id=improving-diffusion-model-speed>Improving Diffusion Model Speed<a hidden class=anchor aria-hidden=true href=#improving-diffusion-model-speed>#</a></h2><h3 id=denoising-diffusion-implicit-model-ddim>Denoising Diffusion Implicit Model (DDIM)<a hidden class=anchor aria-hidden=true href=#denoising-diffusion-implicit-model-ddim>#</a></h3><p>DDIM modifies the original diffusion process to reduce the number of steps needed, speeding up the sampling process without sacrificing sample quality. By altering the noise schedule and denoising steps, DDIM achieves efficient sampling.</p><img loading=lazy src=images/ddim.png alt=DDIM><h3 id=latent-diffusion-model>Latent Diffusion Model<a hidden class=anchor aria-hidden=true href=#latent-diffusion-model>#</a></h3><p>Latent diffusion models operate in a lower-dimensional latent space, significantly enhancing computational efficiency. By mapping data to a latent space before applying the diffusion process, these models reduce the computational burden while maintaining high-quality sample generation.</p><img loading=lazy src=images/latent_diffusion_model.png alt="Latent Diffusion Model"><h2 id=model-architecture>Model Architecture<a hidden class=anchor aria-hidden=true href=#model-architecture>#</a></h2><h3 id=u-net>U-Net<a hidden class=anchor aria-hidden=true href=#u-net>#</a></h3><p>U-Net architecture is commonly used in diffusion models, featuring an encoder-decoder structure with skip connections for preserving high-resolution features. The encoder compresses the input into a lower-dimensional representation, while the decoder reconstructs the original data from this compressed form. Skip connections ensure that fine-grained details are retained throughout the process.</p><img loading=lazy src=images/unet.png alt=U-Net><h3 id=diffusion-transformer-dit>Diffusion Transformer (DiT)<a hidden class=anchor aria-hidden=true href=#diffusion-transformer-dit>#</a></h3><p>DiT combines the strengths of diffusion models with transformer architectures, enabling efficient processing of sequential data. This hybrid model leverages the attention mechanism of transformers to capture long-range dependencies, improving the quality of generated samples.</p><img loading=lazy src=images/dit.png alt="Diffusion Transformer"><h2 id=implementation>Implementation<a hidden class=anchor aria-hidden=true href=#implementation>#</a></h2><p>Implementation details of diffusion models involve various techniques and optimizations, tailored to the specific application domain. Key considerations include:</p><ol><li><strong>Noise Schedule</strong>: Choosing an appropriate noise schedule (\( \beta_t \)) is crucial for balancing the trade-off between sample quality and computational efficiency.</li><li><strong>Training Procedure</strong>: Properly training the model requires careful handling of the variational lower bound and the use of advanced optimization techniques.</li><li><strong>Hardware Acceleration</strong>: Leveraging GPUs or TPUs can significantly speed up the training and inference processes, making diffusion models more practical for real-world applications.</li></ol><img loading=lazy src=images/implementation.png alt=Implementation><h2 id=conclusion>Conclusion<a hidden class=anchor aria-hidden=true href=#conclusion>#</a></h2><p>Diffusion models have revolutionized generative modeling, offering robust performance across diverse tasks. Their adaptability and scalability make them a valuable tool in modern machine learning. As research continues to advance, we can expect even greater improvements in the efficiency and capabilities of these models.</p><h2 id=references>References<a hidden class=anchor aria-hidden=true href=#references>#</a></h2><ol><li>Ho, Jonathan, Ajay Jain, and Pieter Abbeel. &ldquo;Denoising Diffusion Probabilistic Models.&rdquo; arXiv preprint arXiv:2006.11239 (2020).</li><li>Song, Jiaming, and Stefano Ermon. &ldquo;Generative Modeling by Estimating Gradients of the Data Distribution.&rdquo; arXiv preprint arXiv:1907.05600 (2019).</li><li>Dhariwal, Prafulla, and Alexander Nichol. &ldquo;Diffusion Models Beat GANs on Image Synthesis.&rdquo; arXiv preprint arXiv:2105.05233 (2021).</li><li>Sohl-Dickstein, Jascha, et al. &ldquo;Deep Unsupervised Learning using Nonequilibrium Thermodynamics.&rdquo; arXiv preprint arXiv:1503.03585 (2015).</li><li>Kingma, Diederik P., and Max Welling. &ldquo;Auto-Encoding Variational Bayes.&rdquo; arXiv preprint arXiv:1312.6114 (2013).</li></ol></div><footer class=post-footer><ul class=post-tags><li><a href=http://localhost:1313/tags/first/>First</a></li></ul></footer></article></main><footer class=footer><span>&copy; 2024 <a href=http://localhost:1313/>Q'Corner</a></span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script></body></html>